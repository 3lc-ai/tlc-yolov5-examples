{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "The first step is to clone the fork, and checkout the branch with the 3LC integration. Set your preferred path, and the next cells will get it cloned and set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLOV5_PATH = \"../../tlc-yolov5\"\n",
    "TLC_PATH = \"../tlc-monorepo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\47468\\repos\\tlc-yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd \"{YOLOV5_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone \"https://3lc-ai@dev.azure.com/3lc-ai/TLC/_git/tlc-yolov5\"\n",
    "!git checkout \"feature/frederik.mellbye/tlc-integration\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the YOLOv5 repository with the 3LC integration cloned, we need to install the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are on Windows and have a GPU it is a good idea to get the correct PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchvision --index-url https://download.pytorch.org/whl/cu118 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -e \"{TLC_PATH}\"\n",
    "%pip install poetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "With everything set up we are now ready to run training with 3LC metrics collection. Let's first take a look at the extra 3LC command line arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train.py [-h] [--weights WEIGHTS] [--cfg CFG] [--data DATA] [--hyp HYP]\n",
      "                [--epochs EPOCHS] [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
      "                [--rect] [--resume [RESUME]] [--nosave] [--noval]\n",
      "                [--noautoanchor] [--noplots] [--evolve [EVOLVE]]\n",
      "                [--bucket BUCKET] [--cache [CACHE]] [--image-weights]\n",
      "                [--device DEVICE] [--multi-scale] [--single-cls]\n",
      "                [--optimizer {SGD,Adam,AdamW}] [--sync-bn] [--workers WORKERS]\n",
      "                [--project PROJECT] [--name NAME] [--exist-ok] [--quad]\n",
      "                [--cos-lr] [--label-smoothing LABEL_SMOOTHING]\n",
      "                [--patience PATIENCE] [--freeze FREEZE [FREEZE ...]]\n",
      "                [--save-period SAVE_PERIOD] [--seed SEED]\n",
      "                [--local_rank LOCAL_RANK] [--tlc-disable-mc]\n",
      "                [--tlc-mc-interval TLC_MC_INTERVAL]\n",
      "                [--tlc-mc-start TLC_MC_START] [--tlc-mc-before-training]\n",
      "                [--tlc-mc-iou-thres TLC_MC_IOU_THRES]\n",
      "                [--tlc-mc-conf-thres TLC_MC_CONF_THRES]\n",
      "                [--tlc-mc-nms-iou-thres TLC_MC_NMS_IOU_THRES]\n",
      "                [--tlc-mc-max-det TLC_MC_MAX_DET] [--tlc-mc-model-ema]\n",
      "                [--tlc-project-name TLC_PROJECT_NAME]\n",
      "                [--tlc-train-revision TLC_TRAIN_REVISION]\n",
      "                [--tlc-val-revision TLC_VAL_REVISION] [--entity ENTITY]\n",
      "                [--upload_dataset [UPLOAD_DATASET]]\n",
      "                [--bbox_interval BBOX_INTERVAL]\n",
      "                [--artifact_alias ARTIFACT_ALIAS]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --weights WEIGHTS     initial weights path\n",
      "  --cfg CFG             model.yaml path\n",
      "  --data DATA           dataset.yaml path\n",
      "  --hyp HYP             hyperparameters path\n",
      "  --epochs EPOCHS       total training epochs\n",
      "  --batch-size BATCH_SIZE\n",
      "                        total batch size for all GPUs, -1 for autobatch\n",
      "  --imgsz IMGSZ, --img IMGSZ, --img-size IMGSZ\n",
      "                        train, val image size (pixels)\n",
      "  --rect                rectangular training\n",
      "  --resume [RESUME]     resume most recent training\n",
      "  --nosave              only save final checkpoint\n",
      "  --noval               only validate final epoch\n",
      "  --noautoanchor        disable AutoAnchor\n",
      "  --noplots             save no plot files\n",
      "  --evolve [EVOLVE]     evolve hyperparameters for x generations\n",
      "  --bucket BUCKET       gsutil bucket\n",
      "  --cache [CACHE]       image --cache ram/disk\n",
      "  --image-weights       use weighted image selection for training\n",
      "  --device DEVICE       cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
      "  --multi-scale         vary img-size +/- 50%\n",
      "  --single-cls          train multi-class data as single-class\n",
      "  --optimizer {SGD,Adam,AdamW}\n",
      "                        optimizer\n",
      "  --sync-bn             use SyncBatchNorm, only available in DDP mode\n",
      "  --workers WORKERS     max dataloader workers (per RANK in DDP mode)\n",
      "  --project PROJECT     save to project/name\n",
      "  --name NAME           save to project/name\n",
      "  --exist-ok            existing project/name ok, do not increment\n",
      "  --quad                quad dataloader\n",
      "  --cos-lr              cosine LR scheduler\n",
      "  --label-smoothing LABEL_SMOOTHING\n",
      "                        Label smoothing epsilon\n",
      "  --patience PATIENCE   EarlyStopping patience (epochs without improvement)\n",
      "  --freeze FREEZE [FREEZE ...]\n",
      "                        Freeze layers: backbone=10, first3=0 1 2\n",
      "  --save-period SAVE_PERIOD\n",
      "                        Save checkpoint every x epochs (disabled if < 1)\n",
      "  --seed SEED           Global training seed\n",
      "  --local_rank LOCAL_RANK\n",
      "                        Automatic DDP Multi-GPU argument, do not modify\n",
      "  --tlc-disable-mc, --tlc-disable-metrics-collection\n",
      "                        Disable 3LC metrics collection.\n",
      "  --tlc-mc-interval TLC_MC_INTERVAL, --tlc-metrics-collection-interval TLC_MC_INTERVAL\n",
      "                        Epoch interval between metrics collections.\n",
      "  --tlc-mc-start TLC_MC_START, --tlc-metrics-collection-start TLC_MC_START\n",
      "                        Epoch to start collecting metrics. Defaults to first\n",
      "                        epoch (0).\n",
      "  --tlc-mc-before-training, --tlc-metrics-collection-before-training\n",
      "                        Collect metrics before training.\n",
      "  --tlc-mc-iou-thres TLC_MC_IOU_THRES, --tlc-metrics-collection-iou-threshold TLC_MC_IOU_THRES\n",
      "                        IoU threshold for 3LC metrics collection.\n",
      "  --tlc-mc-conf-thres TLC_MC_CONF_THRES, --tlc-metrics-collection-confidence-threshold TLC_MC_CONF_THRES\n",
      "                        NMS Confidence threshold for metrics collection\n",
      "  --tlc-mc-nms-iou-thres TLC_MC_NMS_IOU_THRES, --tlc-metrics-collection-nms-iou-threshold TLC_MC_NMS_IOU_THRES\n",
      "                        IoU threshold for metrics collection NMS\n",
      "  --tlc-mc-max-det TLC_MC_MAX_DET, --tlc-metrics-collection-max-det TLC_MC_MAX_DET\n",
      "                        Maximum number of detections per image for metrics\n",
      "                        collection\n",
      "  --tlc-mc-model-ema, --tlc-metrics-collection-model-ema\n",
      "                        Use exponential moving average of model weights for\n",
      "                        metrics collection instead of latest model.\n",
      "  --tlc-project-name TLC_PROJECT_NAME\n",
      "                        Name of the project in 3LC. Inferred by default from\n",
      "                        dataset YAML file.\n",
      "  --tlc-train-revision TLC_TRAIN_REVISION\n",
      "                        Train dataset revision, defaults to latest.\n",
      "  --tlc-val-revision TLC_VAL_REVISION\n",
      "                        Validation dataset revision, defaults to latest.\n",
      "  --entity ENTITY       Entity\n",
      "  --upload_dataset [UPLOAD_DATASET]\n",
      "                        Upload data, \"val\" option\n",
      "  --bbox_interval BBOX_INTERVAL\n",
      "                        Set bounding-box image logging interval\n",
      "  --artifact_alias ARTIFACT_ALIAS\n",
      "                        Version of dataset artifact to use\n"
     ]
    }
   ],
   "source": [
    "!python train.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train a YOLOv5n model on COCO128 for ten epochs, collecting metrics every five epochs starting after the fifth. 3LC will automatically read the dataset, and present it back to YOLOv5 which performs training and calls metrics collection. This will result in two 3LC Tables, for the train and validation splits, along with a Run associated with the Tables which contains the collected metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 640 --batch 32 --epochs 10 --data coco128.yaml --weights yolov5n.pt --nosave --tlc-mc-start 4 --tlc-mc-interval 5 --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to collect metrics independently of training with `collect.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: collect.py [-h] [--data DATA] [--weights WEIGHTS [WEIGHTS ...]]\n",
      "                  [--imgsz IMGSZ] [--conf-thres CONF_THRES]\n",
      "                  [--iou-thres IOU_THRES] [--max-det MAX_DET] [--split SPLIT]\n",
      "                  [--device DEVICE] [--workers WORKERS] [--single-cls]\n",
      "                  [--augment] [--half] [--dnn] [--tlc-iou-thres TLC_IOU_THRES]\n",
      "                  [--tlc-revision-url TLC_REVISION_URL]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --data DATA           dataset.yaml path\n",
      "  --weights WEIGHTS [WEIGHTS ...]\n",
      "                        model path(s)\n",
      "  --imgsz IMGSZ, --img IMGSZ, --img-size IMGSZ\n",
      "                        inference size (pixels)\n",
      "  --conf-thres CONF_THRES\n",
      "                        confidence threshold\n",
      "  --iou-thres IOU_THRES\n",
      "                        NMS IoU threshold\n",
      "  --max-det MAX_DET     maximum detections per image\n",
      "  --split SPLIT         Split to collect metrics for\n",
      "  --device DEVICE       cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
      "  --workers WORKERS     max dataloader workers (per RANK in DDP mode)\n",
      "  --single-cls          treat as single-class dataset\n",
      "  --augment             augmented inference\n",
      "  --half                use FP16 half-precision inference\n",
      "  --dnn                 use OpenCV DNN for ONNX inference\n",
      "  --tlc-iou-thres TLC_IOU_THRES\n",
      "                        IoU threshold for 3LC to consider a prediction a match\n",
      "  --tlc-revision-url TLC_REVISION_URL\n",
      "                        URL to the revision of the 3LC dataset to collect\n",
      "                        metrics for\n"
     ]
    }
   ],
   "source": [
    "!python collect.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python collect.py --data coco128.yaml --weights yolov5n.pt --img 640 --device 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should see both your runs in the 3LC Dashboard, look for the names you see in the outputs above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
